---
title: "Homework 4"
author: "Caroline Dennington"
date: "2024-04-05"
output: word_document
---

---
title: "Homework 4"
author: "Caroline Dennington"
date: "2024-04-04"
output: word_document
---

# Problem 1

## Part A

An input analysis is performed for all three variables to determine what input distributions are an appropriate fit. When analyzing Failure Count, the distribution appeared to be discrete and the distribution had a positive skew. The Auto correlation function (ACF) plot shows that the Failure Count data is uncorrelated with itself, as none of the lags are significantly out of the confidence bounds. There is one lag that is out of the confidence bounds, but it's ACF is below 0.2. The descdist() function is then used to visualize the kurtosis and square skewness of the observed distribution compared to various discrete distribution types. This is what is known as a Cullen and Frey graph. This visualization indicates that the observed distribution is most similar to the normal and Poisson distributions. 

When comparing the p-values for probability that the observed distribution is a Poisson or normal distribution, only the Poisson distribution had a p-value that was large enough to reject the null hypothesis (that the observed distribution is of the same type) at the 95% confidence level. The p-value for failure count having a normal distribution is approximately 2.8e-5, whereas the p-value for the data having a Poisson distribution is approximately 0.77. Therefor the Poisson distribution is selected to use for simulating values of Failure Count. The Poisson distribution has a lambda of 2.93 and a standard error of 0.1210372.


```{r}
# load the data
git <- "https://raw.githubusercontent.com/cld3033/"
path <- "-Simulation-Optimization/main/M4%3A%20Data%20Driven%20Monte%20Carlo%20Simulation/"
file <- "windTurbineData(3).csv"
turbine <- read.csv(paste0(git, path, file))


######## failure count input analysis ###############

# 1. Determine if the data is discrete or continuous
turbine$failure.count # data appears to be discrete

# 2. Visualize the data 
hist(turbine$failure.count, main = "Historical Failure Count") # The distribution has a positive skew and appears to be unimodal

plot(turbine$failure.count, type = "b", main = "Historical Failure Count", 
     ylab = "Count", xlab = "Year")
# The data appears to be random in the time series plot
# The data points are independent of each other 

acf(turbine$failure.count, main = "ACF Plot for Turbine Failures") 
# lag 5 is out of the confidence band. However, the correlation is still very low.
# This suggests that the data does not have correlation with itself.

# 3. Hypothesize the distribution
library(fitdistrplus)
descdist(turbine$failure.count, discrete = TRUE)
# Poisson appears to be closest, but normal also is very close.

failFit.pois <- fitdist(turbine$failure.count, "pois")
summary(failFit.pois)
gofstat(failFit.pois)
# Fail to reject the null hypothesis that this is a good dist.

failFit.norm <- fitdist(turbine$failure.count, "norm")
summary(failFit.norm)
g <- gofstat(failFit.norm)
g$chisqpvalue
# reject the hypothesis that normal distribution is a good fit 

plot(failFit.norm)
plot(failFit.pois)
# Poisson distribution will be best for failure Count


```

Input analysis is performed for repair time in the same manor. When observing the data points for the repair time variable, they appear to be continuous. This histogram of the data has a uniform distribution. The time series plot of the data reveals no relationship with repair time and year. The ACF plot also shows all lags to be within the confidence bounds, indicating that the data is IID. 

When view the Cullen and Frey graph the data, it is observed that the distribution of the repair time data has a skewness and kurtosis most similar to the normal and gamma distributions. The hypothesis test is conducted for repair time data having the same distribution is conducted for each distribution. Both hypothesis tests result in a p-value that is too large to reject the null hypothesis that the distribution of repair time and the tested distribution are the same at the 95% confidence level. The p-value for the normal distribution test is approximately 0.09, whereas the p-vlaue for the gamma distribution test is approximately 0.12. The normal distribution has a slightly higher log-likelihood (-365.9681) than the gamma distribution (-366.5354).

Thus the distribution selected for repair time is a normal distribution with a mean of 10.0495 an a standard deviation of 1.508.

```{r}
################## repair time input analysis #######################################

# 1. Determine if the data is discrete or continuous
turbine$rapair.time # data appears to be continuous

# 2. Visualize the data
hist(turbine$rapair.time, main = "Historical Repair Time")
# The data appears to have a normal distribution

plot(turbine$rapair.time, type = "b", main = "Historical Repair Time", 
     ylab = "Count", xlab = "Year") # There does not appear to be a pattern

acf(turbine$rapair.time, main = "ACF Plot for Repair Time")
# All lags are within the confidence band. The data is stationary and is uncorrelated
# with itself.

# 3. Hypothesize the distribution
descdist(turbine$rapair.time, discrete = FALSE)
# normal distribution appears to be closest, but I will try gamma just in case.

repairFit.norm <- fitdist(turbine$rapair.time, "norm")
summary(repairFit.norm)
g2 <- gofstat(repairFit.norm)
g2$chisqpvalue

repairFit.gamma <- fitdist(turbine$rapair.time, "gamma")
summary(repairFit.gamma)
g3 <- gofstat(repairFit.gamma)
g3$chisqpvalue

plot(repairFit.norm)
plot(repairFit.gamma)

repairFit.norm$loglik
repairFit.gamma$loglik
# normal distribution has a slightly better log-likelihood.


```

Input analysis is conducted for the drive time data. The data appears to be continuous on initial inspection. A histogram is then plotted and reveals a distribution that appears to be uniform with slight variation due to randomness. The ACF plot is a v

```{r}
################## Drive time input analysis #######################################

# 1. Determine if the data is discrete or continuous
turbine$drive.time # Data appears to be continuous

# 2. Visualize the data
hist(turbine$drive.time, main = "Historical Drive Time")
# The data almost looks like its uniform

plot(turbine$drive.time, type = "b", main = "Historical Drive Time", 
     ylab = "Count", xlab = "Year") # There does not appear to be a pattern

acf(turbine$drive.time, main = "ACF Plot for Drive Time")
# All lags are within the confidence band. The data is stationary and is uncorrelated
# with itself.

# 3. Hypothesize the distribution
descdist(turbine$drive.time, discrete = FALSE) # appears to be uniform

driveFit.unif <- fitdist(turbine$drive.time, "unif")
summary(driveFit.unif)
g4 <- gofstat(driveFit.unif)
g4$chisqpvalue
plot(driveFit.unif)

driveFit.norm <- fitdist(turbine$drive.time, "norm")
summary(driveFit.norm)
g5 <- gofstat(driveFit.norm)
g5$chisqpvalue
plot(driveFit.norm)

# Uniform distribution is the best fit for drive time 

```

# Problem 3 

## Part A  and B

```{r}
git <- "https://raw.githubusercontent.com/cld3033/"
path <- "-Simulation-Optimization/main/M4%3A%20Data%20Driven%20Monte%20Carlo%20Simulation/"
file <- "newsVendorData(1).csv"
histDemand <- read.csv(paste0(git, path, file))
hist_D <- histDemand$demand

# deterministic variables
C = 12 # cost 
R = 18 # selling price
S = 10 # salvage price

hist(hist_D, main = "Historical Demand of Newspapers", xlab = "Demand")
# This helps me select a range of Qs to test. 30-50 seems like a good range. 

# Create net profit function 
# net profit = min(Q, D)*R + max(0, Q-D)*S - Q*C
netProfitFun <- function(D, Q, R, S, C){
  R*min(Q, D) + S*max(0, Q-D) - Q*C
}

num_sim <- 1000
Qrange <- 30:50
set.seed(123)

# Create a function that will generate bootstrap samples the same size as the original data
boot_sample <- function(x){
  sim_D = sample(x, replace = TRUE)
}

# generate the bootstrap samples
sim_D <- replicate(num_sim, boot_sample(hist_D))


j = 0
new_num_sim <- length(sim_D) # This will allow for a net profit to be calculated 
# for ever vlaue in sim_D
profitMatrix <- matrix(0, nrow = new_num_sim, ncol = length(Qrange))

for (Q in Qrange) {
  j = j+1
  for (i in 1:new_num_sim) {
    profitMatrix[i, j] = netProfitFun(sim_D[i], Q, R, S, C)
  }
}
# Expected (average) profit for each Q
profit_for_each_Q <- colMeans(profitMatrix)
cbind(Qrange, profit_for_each_Q)

best_Q_index <- which.max(profit_for_each_Q)
plot(Qrange, colMeans(profitMatrix), ylab = "Expected Profit", xlab = "Q")

# Optimal purchase quantity is 45

# The 95% confidence interval of maximum profit is:
quantile(profitMatrix[, best_Q_index], c(0.025, 0.975))

hist(profitMatrix[, best_Q_index], main = "Simulated Net Profit when Q = 45", 
     xlab = "Net Profit")
abline(v = max(profit_for_each_Q), col = "blue")
abline(v =  134 , col = "red")
abline(v =  270 , col = "red")
```
